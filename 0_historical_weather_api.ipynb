{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T22:05:08.168625Z",
     "start_time": "2019-11-26T22:05:07.292599Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import copy\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T22:05:08.179613Z",
     "start_time": "2019-11-26T22:05:08.171612Z"
    }
   },
   "outputs": [],
   "source": [
    "# gathering data from 1/1/2017 - 11/20/2019 for initial analysis;\n",
    "# forecasts from this API began getting collected on 11/19/2019;\n",
    "# in reality the time series analysis would need to rely on\n",
    "# forecasts for future periods, but historical forecasts aren't available,\n",
    "# so historical periods will have the unfair advantage of using true weather data\n",
    "# the API calls need to be broken into two batches to stay within\n",
    "# the free-tier of the API service which is capped at 1000 calls/day \n",
    "DAY_LENGTH = 86400\n",
    "TOTAL_DAY_COUNT = 1054\n",
    "FIRST_START_DAY = 1483272000\n",
    "FIRST_PASS_DAY_COUNT = 730\n",
    "second_start_day = FIRST_START_DAY + FIRST_PASS_DAY_COUNT * DAY_LENGTH\n",
    "second_pass_day_count = TOTAL_DAY_COUNT - FIRST_PASS_DAY_COUNT\n",
    "# getting 2015 and 2016 data, which include a leap year\n",
    "older_start_day = FIRST_START_DAY - (FIRST_PASS_DAY_COUNT + 1) * DAY_LENGTH\n",
    "older_pass_day_count = FIRST_PASS_DAY_COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T22:05:08.189614Z",
     "start_time": "2019-11-26T22:05:08.183612Z"
    }
   },
   "outputs": [],
   "source": [
    "first_pass_times = [FIRST_START_DAY]\n",
    "for day in range(0, FIRST_PASS_DAY_COUNT):\n",
    "    sample_time = first_pass_times[-1] + DAY_LENGTH\n",
    "    first_pass_times.append(sample_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T22:05:08.201613Z",
     "start_time": "2019-11-26T22:05:08.195616Z"
    }
   },
   "outputs": [],
   "source": [
    "second_pass_times = [second_start_day]\n",
    "for day in range(0, second_pass_day_count):\n",
    "    sample_time = second_pass_times[-1] + DAY_LENGTH\n",
    "    second_pass_times.append(sample_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T22:05:08.210615Z",
     "start_time": "2019-11-26T22:05:08.204615Z"
    }
   },
   "outputs": [],
   "source": [
    "older_pass_times = [older_start_day]\n",
    "for day in range(0, older_pass_day_count):\n",
    "    sample_time = older_pass_times[-1] + DAY_LENGTH\n",
    "    older_pass_times.append(sample_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T22:05:08.219620Z",
     "start_time": "2019-11-26T22:05:08.213611Z"
    }
   },
   "outputs": [],
   "source": [
    "# gathering API key from hidden location\n",
    "with open(\"/Users/natha/.secret/dark_sky_api.json\") as api_key_file:\n",
    "    api_key = str(json.load(api_key_file)['api_key'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T22:05:08.226611Z",
     "start_time": "2019-11-26T22:05:08.222611Z"
    }
   },
   "outputs": [],
   "source": [
    "# establishing relevant strings for use in the API call\n",
    "url_base = 'https://api.darksky.net/forecast/'\n",
    "location = '38.8483,-77.0342'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T22:05:08.236611Z",
     "start_time": "2019-11-26T22:05:08.229611Z"
    }
   },
   "outputs": [],
   "source": [
    "def label_historicalType_and_precipType(api_json_data):\n",
    "    \"\"\"\n",
    "    Function loops through the hourly records in the input\n",
    "    json data to label the data as a historical 'type',\n",
    "    and to populate the 'precipType' with 'none' if this\n",
    "    key-value pair is not present, which occurs when there\n",
    "    was no precipitation at that time.\n",
    "    \"\"\"\n",
    "    data_records = api_json_data['hourly']['data']\n",
    "    for record in data_records:\n",
    "        record.update({'type': 'historical'})\n",
    "        try:\n",
    "            record.update({'precipType': record['precipType']})\n",
    "        except:\n",
    "            record.update({'precipType': 'none'})\n",
    "    return data_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T22:05:08.245612Z",
     "start_time": "2019-11-26T22:05:08.239618Z"
    }
   },
   "outputs": [],
   "source": [
    "def api_dataframe_conversion(json_data, hourly_records, column_headers):\n",
    "    \"\"\"\n",
    "    Function generates a dataframe from the hourly historical\n",
    "    weather records for the given day and also provides\n",
    "    locational and type (e.g. historical or forecast) designations.\n",
    "    \"\"\"\n",
    "    data_frame = pd.DataFrame(hourly_records)\n",
    "    data_frame['time'] = pd.to_datetime(data_frame['time'],unit='s')\n",
    "    data_frame['latitude'] = json_data['latitude']\n",
    "    data_frame['longitude'] = json_data['longitude']\n",
    "    data_frame['timezone'] = json_data['timezone']\n",
    "    data_frame = data_frame[column_headers]\n",
    "    data_frame.set_index('time', inplace=True)\n",
    "    return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T22:05:08.259614Z",
     "start_time": "2019-11-26T22:05:08.248611Z"
    }
   },
   "outputs": [],
   "source": [
    "def historical_dataframe_from_api_calls(list_of_times, url_base, api_key, location):\n",
    "    \"\"\"\n",
    "    Function loops through the list of times provided and\n",
    "    returns a dataframe with hourly data from the date when\n",
    "    each time occurs.\n",
    "    \"\"\"\n",
    "    # initializing the final dataframe\n",
    "    column_headers = ['time', 'latitude', 'longitude', 'timezone', 'type', 'summary', 'icon',\n",
    "                      'precipIntensity', 'precipProbability', 'precipType', 'temperature',\n",
    "                      'apparentTemperature', 'dewPoint', 'humidity', 'pressure', 'windSpeed',\n",
    "                      'windGust', 'windBearing', 'cloudCover', 'uvIndex', 'visibility']\n",
    "    historical_data_frame = pd.DataFrame(columns=column_headers)\n",
    "    historical_data_frame.set_index('time', inplace=True)\n",
    "    # looping through the list of times\n",
    "    for time in list_of_times:\n",
    "        url = url_base+api_key+'/'+location+','+str(time)+'?exclude=currently,minutely,daily,alerts,flags'\n",
    "        response = requests.get(url)\n",
    "        data = response.json()\n",
    "        hourly_data = label_historicalType_and_precipType(data)\n",
    "        time_data_frame = api_dataframe_conversion(data, hourly_data, column_headers)\n",
    "        historical_data_frame = historical_data_frame.append(time_data_frame, sort=False)\n",
    "    return historical_data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T22:05:08.265612Z",
     "start_time": "2019-11-26T22:05:08.261610Z"
    }
   },
   "outputs": [],
   "source": [
    "# def label_forecastType_and_precipType(api_json_data):\n",
    "#     \"\"\"\n",
    "#     Function loops through the hourly records in the input\n",
    "#     json data to label the data as a historical 'type',\n",
    "#     and to populate the 'precipType' with 'none' if this\n",
    "#     key-value pair is not present, which occurs when there\n",
    "#     was no precipitation at that time.\n",
    "#     \"\"\"\n",
    "#     data_records = api_json_data['hourly']['data']\n",
    "#     for record in data_records:\n",
    "#         record.update({'type': 'forecast'})\n",
    "#         try:\n",
    "#             record.update({'precipType': record['precipType']})\n",
    "#         except:\n",
    "#             record.update({'precipType': 'none'})\n",
    "#     return data_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T22:05:08.274612Z",
     "start_time": "2019-11-26T22:05:08.269611Z"
    }
   },
   "outputs": [],
   "source": [
    "# def forecast_dataframe_from_api_calls(list_of_times):\n",
    "#     \"\"\"\n",
    "#     Function loops through the list of times provided and\n",
    "#     returns a dataframe with hourly data from the date when\n",
    "#     each time occurs.\n",
    "#     \"\"\"\n",
    "#     # initializing the final dataframe\n",
    "#     column_headers = ['time', 'latitude', 'longitude', 'timezone', 'type', 'summary', 'icon',\n",
    "#                       'precipIntensity', 'precipProbability', 'precipType', 'temperature',\n",
    "#                       'apparentTemperature', 'dewPoint', 'humidity', 'pressure', 'windSpeed',\n",
    "#                       'windGust', 'windBearing', 'cloudCover', 'uvIndex', 'visibility']\n",
    "#     forecast_data_frame = pd.DataFrame(columns=column_headers)\n",
    "#     forecast_data_frame.set_index('time', inplace=True)\n",
    "#     # looping through the list of times\n",
    "#     for time in list_of_times:\n",
    "#         url = url_base+api_key+'/'+location+','+str(time)+'?exclude=currently,minutely,daily,alerts,flags'\n",
    "#         response = requests.get(url)\n",
    "#         data = response.json()\n",
    "#         hourly_data = label_forecastType_and_precipType(data)\n",
    "#         time_data_frame = api_dataframe_conversion(data, hourly_data, column_headers)\n",
    "#         forecast_data_frame = forecast_data_frame.append(time_data_frame, sort=False)\n",
    "#     return forecast_data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T22:05:08.281614Z",
     "start_time": "2019-11-26T22:05:08.277614Z"
    }
   },
   "outputs": [],
   "source": [
    "# df1 = historical_dataframe_from_api_calls(first_pass_times, url_base, api_key, location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T22:05:08.290618Z",
     "start_time": "2019-11-26T22:05:08.284612Z"
    }
   },
   "outputs": [],
   "source": [
    "# df1.to_csv('data/KDCA_weather_data_2017-2018.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T22:05:08.297612Z",
     "start_time": "2019-11-26T22:05:08.293615Z"
    }
   },
   "outputs": [],
   "source": [
    "# df2 = historical_dataframe_from_api_calls(second_pass_times, url_base, api_key, location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T22:05:08.306611Z",
     "start_time": "2019-11-26T22:05:08.301613Z"
    }
   },
   "outputs": [],
   "source": [
    "# df2.to_csv('data/KDCA_weather_data_2019-20191121.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T22:07:02.353051Z",
     "start_time": "2019-11-26T22:05:08.309611Z"
    }
   },
   "outputs": [],
   "source": [
    "df2 = historical_dataframe_from_api_calls(older_pass_times, url_base, api_key, location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-26T22:07:02.653030Z",
     "start_time": "2019-11-26T22:07:02.355921Z"
    }
   },
   "outputs": [],
   "source": [
    "df2.to_csv('data/KDCA_weather_data_2015-2016.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
